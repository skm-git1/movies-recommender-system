{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install surprise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAiVeYpHF-6Y",
        "outputId": "d1fa2c0a-92d0-42c6-fa4d-9f6aed3b2a80"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/154.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.5.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise->surprise) (1.16.0)\n",
            "Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-linux_x86_64.whl size=2469540 sha256=03e60a07ff3cb91be3b4ddcd1dd86fa2d7f160c011501a292ae77b3b8f252192\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/8f/6e/7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.4 surprise-0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5IRAzrFEkx8",
        "outputId": "ae4f855e-ab8a-4e2d-fe27-96ef5c65c928"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading TMDB content data...\n",
            "Loaded TMDB data with 4803 movies\n",
            "Loading MovieLens data...\n",
            "Loaded MovieLens: 9742 movies, 100836 ratings\n",
            "Merging datasets...\n",
            "Merged dataset size: (2838, 5)\n",
            "Training collaborative filtering model...\n",
            "CF model trained.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# ---------- Utility Functions ----------\n",
        "def clean_title(title):\n",
        "    title = re.sub(r\"\\(\\d{4}\\)\", \"\", title)\n",
        "    title = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", title)\n",
        "    return title.lower().strip()\n",
        "\n",
        "# ---------- Content-Based Components ----------\n",
        "def load_tmdb_content(tmdb_movies_path, tmdb_credits_path):\n",
        "    # Load and merge TMDB metadata\n",
        "    movies = pd.read_csv(tmdb_movies_path)\n",
        "    credits = pd.read_csv(tmdb_credits_path)\n",
        "    movies = movies.merge(credits, left_on='id', right_on='movie_id')\n",
        "\n",
        "    # Print columns to debug\n",
        "    # print(\"Columns after merging movies and credits:\")\n",
        "    # print(movies.columns)\n",
        "\n",
        "    # Extract relevant features\n",
        "    def parse_list(x):\n",
        "        try:\n",
        "            items = eval(x)\n",
        "            return \" \".join([i['name'].replace(\" \", \"\") for i in items])\n",
        "        except:\n",
        "            return ''\n",
        "\n",
        "    movies['genres'] = movies['genres'].apply(parse_list)\n",
        "    movies['keywords'] = movies['keywords'].apply(parse_list)\n",
        "    movies['cast']     = movies['cast'].apply(lambda x: parse_list(x).split()[:5])\n",
        "    movies['cast']     = movies['cast'].apply(lambda x: \" \".join(x))\n",
        "    # Extract director\n",
        "    def get_director(x):\n",
        "        try:\n",
        "            crew = eval(x)\n",
        "            for member in crew:\n",
        "                if member['job'] == 'Director':\n",
        "                    return member['name'].replace(\" \", \"\")\n",
        "        except:\n",
        "            pass\n",
        "        return ''\n",
        "    movies['crew'] = movies['crew'].apply(get_director)\n",
        "\n",
        "    # Combine features\n",
        "    movies['combined_features'] = (\n",
        "        movies['overview'].fillna('') + \" \" +\n",
        "        movies['genres'] + \" \" +\n",
        "        movies['keywords'] + \" \" +\n",
        "        movies['cast'] + \" \" +\n",
        "        movies['crew']\n",
        "    )\n",
        "\n",
        "    # Vectorize\n",
        "    tfidf = TfidfVectorizer(stop_words='english')\n",
        "    tfidf_matrix = tfidf.fit_transform(movies['combined_features'])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "    # Prepare index mapping\n",
        "    movies['clean_title'] = movies['title_x'].apply(clean_title)\n",
        "    movies = movies.reset_index()\n",
        "    return movies, cosine_sim\n",
        "\n",
        "def content_recommend(movies_df, cosine_sim, title, top_n=10):\n",
        "    title = clean_title(title)\n",
        "    if title not in movies_df['clean_title'].values:\n",
        "        raise ValueError(f\"Movie '{title}' not found in TMDB metadata.\")\n",
        "    idx = movies_df[movies_df['clean_title'] == title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
        "    recommended_ids = [i[0] for i in sim_scores]\n",
        "    return movies_df.loc[recommended_ids, 'title_x'].tolist()\n",
        "\n",
        "# ---------- Collaborative Filtering Components ----------\n",
        "def load_movielens_ratings(ml_movies_path, ml_ratings_path):\n",
        "    ml_movies = pd.read_csv(ml_movies_path)\n",
        "    ml_ratings = pd.read_csv(ml_ratings_path)\n",
        "    ml_movies['clean_title'] = ml_movies['title'].apply(clean_title)\n",
        "    return ml_movies, ml_ratings\n",
        "\n",
        "def merge_datasets(tmdb_movies, ml_movies):\n",
        "    # Merge on clean_title\n",
        "    merged = pd.merge(ml_movies, tmdb_movies[['clean_title', 'index']], on='clean_title', how='inner')\n",
        "    merged.rename(columns={'index': 'tmdb_index'}, inplace=True)\n",
        "    return merged\n",
        "\n",
        "def train_cf_model(ratings_df):\n",
        "    reader = Reader(rating_scale=(ratings_df['rating'].min(), ratings_df['rating'].max()))\n",
        "    data = Dataset.load_from_df(ratings_df[['userId', 'movieId', 'rating']], reader)\n",
        "    trainset = data.build_full_trainset()\n",
        "    model = SVD()\n",
        "    model.fit(trainset)\n",
        "    return model\n",
        "\n",
        "# ---------- Hybrid Recommender ----------\n",
        "def hybrid_recommend(user_id, tmdb_movies, cosine_sim, cf_model,\n",
        "                     ml_ratings, merged_df, alpha=0.7, top_n=10):\n",
        "    # Get user's rated movies\n",
        "    user_data = ml_ratings[ml_ratings['userId'] == user_id]\n",
        "    # If user has no history, fallback to popular content-based\n",
        "    if user_data.empty:\n",
        "        print(f\"No ratings for user {user_id}. Providing top content-based recommendations.\")\n",
        "        return tmdb_movies['title_x'].tolist()[:top_n]\n",
        "\n",
        "    # Determine user's favorite movie by highest rating\n",
        "    fav_movie = user_data.sort_values('rating', ascending=False).iloc[0]\n",
        "    fav_movie_id = fav_movie['movieId']\n",
        "\n",
        "    # Check if favorite movie is in the merged dataset (meaning it's in both ML and TMDB)\n",
        "    if fav_movie_id not in merged_df['movieId'].values:\n",
        "        print(f\"Favorite movie (movieId {fav_movie_id}) not found in merged dataset. Falling back to pure collaborative filtering.\")\n",
        "        # Fallback to collaborative filtering\n",
        "        all_movie_ids = ml_movies['movieId'].tolist()\n",
        "        unrated_movie_ids = [mId for mId in all_movie_ids if mId not in user_data['movieId'].values]\n",
        "        predictions = [cf_model.predict(user_id, mId).est for mId in unrated_movie_ids]\n",
        "        top_indices = np.argsort(predictions)[-top_n:][::-1]\n",
        "        top_movie_ids = [unrated_movie_ids[i] for i in top_indices]\n",
        "        top_titles = ml_movies[ml_movies['movieId'].isin(top_movie_ids)]['title'].tolist()\n",
        "        return top_titles\n",
        "\n",
        "    # If favorite movie is in merged dataset, proceed with hybrid approach\n",
        "    tmdb_idx = merged_df[merged_df['movieId'] == fav_movie_id]['tmdb_index'].values[0]\n",
        "\n",
        "    # Candidate movies: those in TMDB\n",
        "    all_indices = list(range(len(tmdb_movies)))\n",
        "    # Compute content scores relative to favorite\n",
        "    content_scores = np.array(cosine_sim[tmdb_idx])\n",
        "\n",
        "    # Collaborative scores: predict for each movieId in ml_movies\n",
        "    cf_scores = []\n",
        "    movie_ids = []\n",
        "    for _, row in merged_df.iterrows():\n",
        "        mId = row['movieId']\n",
        "        if mId in user_data['movieId'].values:\n",
        "            continue  # skip already rated\n",
        "        pred = cf_model.predict(user_id, mId).est\n",
        "        cf_scores.append(pred)\n",
        "        movie_ids.append(mId)\n",
        "\n",
        "    # Align content scores\n",
        "    cont_scores_aligned = []\n",
        "    for mId in movie_ids:\n",
        "        idx = merged_df[merged_df['movieId'] == mId]['tmdb_index'].values[0]\n",
        "        cont_scores_aligned.append(content_scores[idx])\n",
        "\n",
        "    # Normalize scores\n",
        "    cf_arr = np.array(cf_scores)\n",
        "    cf_norm = (cf_arr - cf_arr.min()) / (cf_arr.max() - cf_arr.min())\n",
        "    cont_arr = np.array(cont_scores_aligned)\n",
        "    cont_norm = (cont_arr - cont_arr.min()) / (cont_arr.max() - cont_arr.min())\n",
        "\n",
        "    # Hybrid score\n",
        "    hybrid_score = alpha * cf_norm + (1 - alpha) * cont_norm\n",
        "\n",
        "    # Get top N\n",
        "    top_idx = np.argsort(hybrid_score)[-top_n:][::-1]\n",
        "    top_movie_ids = [movie_ids[i] for i in top_idx]\n",
        "    top_titles = merged_df[merged_df['movieId'].isin(top_movie_ids)]['title'].tolist()\n",
        "    return top_titles\n",
        "\n",
        "# ---------- Main Script ----------\n",
        "if __name__ == '__main__':\n",
        "    # Paths\n",
        "    tmdb_movies_path = 'tmdb_5000_movies.csv'\n",
        "    tmdb_credits_path = 'tmdb_5000_credits.csv'\n",
        "    ml_movies_path = 'ml-latest-small/movies.csv'\n",
        "    ml_ratings_path = 'ml-latest-small/ratings.csv'\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading TMDB content data...\")\n",
        "    tmdb_movies, cosine_sim = load_tmdb_content(tmdb_movies_path, tmdb_credits_path)\n",
        "    print(\"Loaded TMDB data with {} movies\".format(len(tmdb_movies)))\n",
        "\n",
        "    print(\"Loading MovieLens data...\")\n",
        "    ml_movies, ml_ratings = load_movielens_ratings(ml_movies_path, ml_ratings_path)\n",
        "    print(f\"Loaded MovieLens: {len(ml_movies)} movies, {len(ml_ratings)} ratings\")\n",
        "\n",
        "    print(\"Merging datasets...\")\n",
        "    merged = merge_datasets(tmdb_movies, ml_movies)\n",
        "    print(f\"Merged dataset size: {merged.shape}\")\n",
        "\n",
        "    print(\"Training collaborative filtering model...\")\n",
        "    cf_model = train_cf_model(ml_ratings)\n",
        "    print(\"CF model trained.\")\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "user_id = 6\n",
        "print(f\"Hybrid recommendations for user {user_id}:\")\n",
        "recs = hybrid_recommend(user_id, tmdb_movies, cosine_sim, cf_model, ml_ratings, merged, alpha=0.7, top_n=10)\n",
        "for i, title in enumerate(recs, 1):\n",
        "    print(f\"{i}. {title}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMFxMX6DF-CQ",
        "outputId": "12c5b753-36cc-436b-97ee-ad524f8a3376"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid recommendations for user 6:\n",
            "Favorite movie (movieId 318.0) not found in merged dataset. Falling back to pure collaborative filtering.\n",
            "1. Star Wars: Episode IV - A New Hope (1977)\n",
            "2. Star Wars: Episode V - The Empire Strikes Back (1980)\n",
            "3. Amadeus (1984)\n",
            "4. Indiana Jones and the Last Crusade (1989)\n",
            "5. Guess Who's Coming to Dinner (1967)\n",
            "6. Solaris (Solyaris) (1972)\n",
            "7. Beautiful Mind, A (2001)\n",
            "8. City of God (Cidade de Deus) (2002)\n",
            "9. Prisoners (2013)\n",
            "10. Guardians of the Galaxy (2014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba664b13"
      },
      "source": [
        "!pip uninstall numpy -y\n",
        "!pip install numpy==1.26.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bf1ab8a",
        "outputId": "7364341e-77d6-4110-9330-34f71c8e621a"
      },
      "source": [
        "# Check if the favorite movie of user 1 from MovieLens exists in the TMDB dataset\n",
        "fav_movie_id_ml = ml_ratings[ml_ratings['userId'] == user_id].sort_values('rating', ascending=False).iloc[0]['movieId']\n",
        "fav_movie_title_ml = ml_movies[ml_movies['movieId'] == fav_movie_id_ml]['title'].iloc[0]\n",
        "fav_movie_clean_title_ml = clean_title(fav_movie_title_ml)\n",
        "\n",
        "print(f\"User 1's favorite movie (MovieLens): {fav_movie_title_ml} (clean: {fav_movie_clean_title_ml})\")\n",
        "\n",
        "# Check if this movie exists in tmdb_movies based on clean title\n",
        "if fav_movie_clean_title_ml in tmdb_movies['clean_title'].values:\n",
        "    print(f\"'{fav_movie_title_ml}' found in TMDB movies with clean title.\")\n",
        "    # Check if it's in the merged dataset\n",
        "    if fav_movie_id_ml in merged['movieId'].values:\n",
        "        print(f\"'{fav_movie_title_ml}' found in the merged dataset.\")\n",
        "    else:\n",
        "        print(f\"'{fav_movie_title_ml}' NOT found in the merged dataset by movieId.\")\n",
        "else:\n",
        "    print(f\"'{fav_movie_title_ml}' NOT found in TMDB movies by clean title.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 1's favorite movie (MovieLens): M*A*S*H (a.k.a. MASH) (1970) (clean: mash aka mash)\n",
            "'M*A*S*H (a.k.a. MASH) (1970)' NOT found in TMDB movies by clean title.\n"
          ]
        }
      ]
    }
  ]
}